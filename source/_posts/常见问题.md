---
title: 常见问题
date: 2022-08-26 21:10:10
categories: 面试
math: true
tags:
---
<!-- TOC -->

- [c++中的static关键字](#c中的static关键字)
- [c++模板](#c模板)
- [c++深拷贝和浅拷贝的区别](#c深拷贝和浅拷贝的区别)
- [c++多态](#c多态)
- [c++智能指针](#c智能指针)
- [判别模型和生成模型](#判别模型和生成模型)
- [python的垃圾回收机制](#python的垃圾回收机制)
- [转置卷积](#转置卷积)
- [数据集不平衡的处理方式](#数据集不平衡的处理方式)
- [tensorflow和pytorch的区别](#tensorflow和pytorch的区别)
- [图像分类](#图像分类)
- [目标检测](#目标检测)

<!-- /TOC -->
## c++中的static关键字

加载顺序（面向对象）
* 静态->非静态->构造方法
* 父类静态-子类静态-父类非静态-父类构造-子类非静态-子类构造

静态成员变量(面向对象)
* 所有对象共享,不属于某个对象，可以通过类名访问，也可通过对象访问
* 在编译阶段分配内存，分配在数据区（全局区）
* 类内声明，类外初始化(class::var)
* sizeof不会计算静态成员变量

静态成员函数(面向对象)
* 所有对象共享同一个函数
* 静态成员函数只能访问静态成员变量

静态全局变量(面向过程)

* 在数据区分配内存
* 未初始化会自动初始化为0
* 整个文件内可见，文件外不可见

静态局部变量(面向过程)

* 在数据区分配内存 
* 一般在声明处初始化，未初始化会自动初始化为0
* 静态局部变量始终驻留在数据区，但他的作用域是局部作用域，当定义它的函数或语句块结束，其作用域随之结束

>总结：静态变量具有全局变量的生命周期，但只能作用于自己的作用域。

***

## c++模板

>模板是c++泛型编程的主要使用的技术

**函数模板**

创建一个通用的函数，函数返回值类型和形参可以不指定，用一个虚拟的类型来表示

声明一个模板`template<typename T>`或者`template<class T>`

示例：
```
#include<bits/stdc++.h>
using namespace std;
template<typename T>
T sum(T a,T b)
{
	return a+b;
}
int main()
{
	double a=10.5,b=20.00002;
	cout<<"自动类型推导"<<endl;
	printf("%lf\n",sum(a,b));
	cout<<"显示指定类型"<<endl;
	printf("%lf",sum<double>(a,b));
	return 0;
} 
```

注意
* 自动推导类型需要推导出一致的类型
* 函数模板使用时必须确定`T`的类型
* 普通函数和函数模板都可调用时，先调用普通函数
* 如果类型和函数模板更匹配，则优先调用函数模板

**类模板**

示例：
```
#include<bits/stdc++.h>
using namespace std;
template<class T,class M>
class person
{
public:
	T name;
	M age;
	person(T a,M b):name(a),age(b){}
};
int main()
{
	person<string,int> p("cndh",18);
	cout<<p.name<<endl;
	cout<<p.age<<endl;
	return 0;
} 
```
注意：
* 类模板不能自动推导类型
* 类模板可以在模板参数列表中指定默认类型
* 类模板中定义的函数在调用时才创建

---

## c++深拷贝和浅拷贝的区别

>**浅拷贝** （默认方式）：将原对象的引用直接赋给新对象，只是原对象的一个引用。

>**深拷贝**： 创建一个新的对象，将原对象的各项属性拷贝过来，深拷贝会在堆中额外申请内存来储存数据，当数据成员中有指针时，必须要用深拷贝。

* 因为申请了新的内存，所以深拷贝改变新对象的属性对原对象没有影响，但是浅拷贝会影响
* 当成员中有指针时，必须用深拷贝。因为浅拷贝的新指针和旧指针都指向同一块内存，在新对象和旧对象析构时，已经释放的内存会被再次释放，这时会出现错误。

***

## c++多态

编译时多态：在编译期间就确定了程序的行为，比如函数重载

运行时多态：指的是在不同继承关系的类对象去调用同一函数，产生了不同的行为

***override***

override是用来检查函数是否重写

***final***

加在类名后面表示该类不能被继承，加在函数后面表示函数不能被重写

***多继承存在的问题***

命名冲突

***向上转型***

向上转型是子类指针转换成父类指针

`Parent* p =new son();`

***向下转型***

因为父类指针不能操作子类独有的函数，即使父类指针指向子类的对象也不行，所以需要向下转型

向下转型有两种方式`dynamic_cast`和`static_cast`,前者更加安全一些

例如：
```
Parent* pSon=new Son();
Son* s=dynamic_cast<Son*>(pSon);
```

***
## c++智能指针

**内存泄漏**：
* 指因某些原因造成程序未能释放已不再使用的内存。内存泄漏并不是内存消失了，而是由于程序设计的问题，失去对某块内存的控制，导致无法利用该块内存。

* 内存泄漏会导致程序响应越来越慢，甚至崩溃

* 一般有2种内存泄漏，一种是堆区分配的内存没有及时释放，一种是套接字、文件描述符等没有释放，2种情形都会导致资源的浪费

**RALL**

* RAII（Resource Acquisition Is Initialization）是一种将对象生命周期和资源绑定的技术
* 对象创建时获取资源，析构时释放资源

智能指针就具有RALL的特性

**auto_ptr**

c++98中就已经提供了智能指针auto_ptr

例如：`auto_ptr<int> p(new int)`就相当于 `int * p=new int`

auto_ptr的局限性：
* 拷贝或者赋值会导致原指针变为`NULL`，如`p1=p2`后，`p2变成了NULL`
* 不支持对象数组的内存管理

**unique_ptr**



不能直接进行赋值或者拷贝构造，如：`p1 = p2`和`unique_ptr<int> p1(p2)`

如果要强行执行的话要加上`move`，如：`p1 = std::move(p2)`和`unique_ptr<int> p1(std::move(p2))`

**shared_ptr**

通过**引用计数**(`use_count()`)的方式来实现多个`shared_ptr`对象之间共享资源

* shared_ptr在其内部，给每个资源都有一份计数表，用来记录该份资源被几个指针共享
* 在对象被销毁时(也就是析构函数调用)，就说明自己不使用该资源了，对象的引用计数减一
* 如果引用计数是0，就说明自己是最后一个使用该资源的对象，必须释放该资源
* 如果不是0，就说明除了自己还有其他对象在使用该份资源，不能释放该资源，否则其他对象就成野指针了

注意：两个对象交叉使用**shared_ptr**(互相获得对方的share指针),会导致内存泄漏

**weak_ptr**

专门为了解决上面的**shared_ptr**的问题，不支持RALL，不释放资源，不增加或减少引用计数

具体参考[相关链接](https://blog.csdn.net/cpp_learner/article/details/118912592?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166191088916782414982504%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166191088916782414982504&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-118912592-null-null.142^v42^pc_rank_34,185^v2^control&utm_term=c%2B%2B%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88&spm=1018.2226.3001.4187)

***

## 判别模型和生成模型

判别模型：直接学习条件概率$P(y|x)$
生成模型：学习联合概率$P(x,y)$，然后可以计算条件概率$P(y|x)$以及其他信息，需要的数据量较大


简单说，要判断一个苹果是好是坏，判别模型会直接给出是好的概率和是坏的概率，而生成模型分别学习出两种苹果各自对应的模型，然后将要预测的苹果的特征分别输入不同模型，然后比较两个模型输出概率的大小，选出合适的类别

判别模型：
* 感知机
* k近邻
* 决策树
* 逻辑思蒂回归
* svm
* boosting
* 最大熵模型

生成模型：
* 朴素贝叶斯
* 混合高斯模型
* 隐马尔可夫模型

## python的垃圾回收机制
>python采用的是**引用计数**为主，**标记—清除**和**分代收集**为辅的策略。

**引用计数**
每个对象维护一个字段来记录对象被引用的次数，当新的引用指向该对象的时候，引用计数的值加1,当某个引用失效时，引用计数值减一。当引用计数的值为0时，会释放占用的内存空间。

缺点：
* 需要额外的空间维护引用次数
* 对象的循环引用会导致内存泄漏

引用计数增加的情况：

* 对象被创建，例如 a = 23
* 对象被引用，例如 b = a
* 对象被作为参数，传入到一个函数中，例如 fun(a)
* 对象被作为一个元素，存储在容器中

引用计数减少的情况：

* 对象的别名被显式销毁，例如 del a
* 对象的别名被赋予新的对象，例如 a = 24
* 一个对象离开它的作用域，例如 f 的函数执行完毕时，func函数中的局部变量
* 对象所在的容器被销毁，或从容器中删除对象

**分代回收**

* 分代回收是一种以空间换时间的方式，Python将内存根据对象的存活时间划分为不同的集合，每一个集合称为一个代，Python将内存分为了3“代”，分别代表**年轻代**（第0代）、**中年代**（第1代）、**老年代**（第2代），它们对应的是3个链表，它们的垃圾收集频率随着对象的存活时间的增大而减小

* 新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾回收机制就会被触发，把那些可以被回收的对象被回收掉，而那些不会被回收的对象就会被移动到中年代，依次类推， 老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期中。

**标记--清除**

是一种基于追踪回收（tracking GC）技术实现的垃圾回收算法。它分为两个阶段：
 1. 标记阶段，GC会把所有的活动对象打上标记
 2. 把那些没有标记的对象（非活动对象）进行回收

**如何判断哪些是活动对象，哪些是非活动对象？**

对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从跟对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。

## 转置卷积
>在语义分割中，会使用卷积层进行特征提取，然后通过转置卷积做上采样，恢复为原先的尺寸，这样才可以对原来的图像中每个像素都进行分类。**转置卷积不是卷积的逆运算**

基本步骤：

* 在图像**中间**填充s-1行，s为步长
* 在图像**四周**填充k-p-1行，k为卷积和大小，p为padding
* 将kernel上下、左右翻转
* 做正常卷积即可

## 数据集不平衡的处理方式

1. 数据增广
	* 进行一定的旋转缩放
	* RGB三通道提取三张图片
	* 高斯模糊
2. 人工合成数据
3. 给每种类别赋予权值，样本少的类别权值可以大一些，样本多的类别权值小一些

## tensorflow和pytorch的区别

1. tf是谷歌开源的深度学习框架，pytorch是facebook开源的深度学习框架
2. 在tf1.0时，tf只支持静态的计算图，而pytorch支持动态的计算图，但是tf2.0也支持动态计算图了
3. tf的api更详细更丰富，pytorch的代码更简洁
4. tf有tensorboard这样的可视化工具，但实际上现在pytorch也能使用tensorboard

## 图像分类

## 目标检测

**一阶段方法**

>对于输入图像，通过网络直接回归出目标大小、位置和类别。如SSD、YOLO系列

**二阶段方法**

>先成可能的候选框，然后进行分类，进一步校正候选框，如RCNN，FAST-RCNN，FASTER-RCNN，MASK-RCNN等

**selective search**
>主要是将较为相似的小区域合并，并生成这些区域的边界框

**RCNN**
* 通过selective search生成RP(region proposal)
* 通过cnn对每个RP提取特征
* 通过svm进行分类
* 对完成分类的候选框进行更精确的定位，确定最终的候选框

**Fast RCNN**
* 对整张图像提取特征，不用每个候选框都提取
* 通过selective search 生成候选框映射到featuremap中
* 通过roi pooling生成固定尺寸的featuremap
* 通过softmax进行分类
* 通过NMS校正候选框

**Faster Rcnn**
* 使用RPN替代了selective research,提高了速度
* RPN过程中，每个像素生成若干个锚框，然后生成稍微准确一些的候选框
* 将这些候选框映射到featuremap中
* 后续步骤与fast rcnn相同

**mask rcnn**


**SSD**
