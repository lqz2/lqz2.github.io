---
title: 常见问题
date: 2022-08-26 21:10:10
categories: 面试
math: true
tags:
---
<!-- TOC -->

- [CS基础](#cs基础)
    - [进程和线程的区别](#进程和线程的区别)
- [C++](#c)
    - [c++中的static关键字](#c中的static关键字)
    - [c++模板](#c模板)
    - [c++深拷贝和浅拷贝的区别](#c深拷贝和浅拷贝的区别)
    - [c++多态](#c多态)
    - [虚函数与纯虚函数](#虚函数与纯虚函数)
    - [c++智能指针](#c智能指针)
    - [const 和 volatile辨析](#const-和-volatile辨析)
    - [NULL 和 nullptr的区别是什么，为什么引入nulllptr？](#null-和-nullptr的区别是什么为什么引入nulllptr)
    - [git fetch和git pull的区别](#git-fetch和git-pull的区别)
    - [delete[]是怎样知道数组长度的？](#delete是怎样知道数组长度的)
    - [程序是从main 函数开始执行的吗？](#程序是从main-函数开始执行的吗)
- [python](#python)
    - [python的垃圾回收机制](#python的垃圾回收机制)
- [deep learning](#deep-learning)
    - [判别模型和生成模型](#判别模型和生成模型)
    - [转置卷积和空洞卷积](#转置卷积和空洞卷积)
    - [数据集不平衡的处理方式](#数据集不平衡的处理方式)
    - [tensorflow和pytorch的区别](#tensorflow和pytorch的区别)
    - [transformer中的位置编码](#transformer中的位置编码)
    - [自注意力和注意力的区别](#自注意力和注意力的区别)

<!-- /TOC -->
# CS基础
## 进程和线程的区别
>进程是资源分配的基本单位，线程是资源调度的基本单位(轻量级进程)

* 多个线程共享地址空间/资源，而进程之间的地址空间/资源是独立的
* 一个线程只能属于一个进程，一个进程可以有多个线程
* 创建/撤销线程的系统开销明显小于进程


# C++
## c++中的static关键字

加载顺序（面向对象）
* 静态->非静态->构造方法
* 父类静态-子类静态-父类非静态-父类构造-子类非静态-子类构造

静态成员变量(面向对象)
* 所有对象共享,不属于某个对象，可以通过类名访问，也可通过对象访问
* 在编译阶段分配内存，分配在数据区（全局区）
* 类内声明，类外初始化(class::var)
* sizeof不会计算静态成员变量

静态成员函数(面向对象)
* 所有对象共享同一个函数
* 静态成员函数只能访问静态成员变量
* 不含this指针(不能被实例使用)

静态全局变量(面向过程)

* 在数据区分配内存
* 未初始化会自动初始化为0
* 整个文件内可见，文件外不可见

静态局部变量(面向过程)

* 在数据区分配内存 
* 一般在声明处初始化，未初始化会自动初始化为0
* 静态局部变量始终驻留在数据区，但他的作用域是局部作用域，当定义它的函数或语句块结束，其作用域随之结束

>总结：静态变量具有全局变量的生命周期，但只能作用于自己的作用域。

***

## c++模板

>模板是c++泛型编程的主要使用的技术

**函数模板**

创建一个通用的函数，函数返回值类型和形参可以不指定，用一个虚拟的类型来表示

声明一个模板`template<typename T>`或者`template<class T>`

示例：
```
#include<bits/stdc++.h>
using namespace std;
template<typename T>
T sum(T a,T b)
{
	return a+b;
}
int main()
{
	double a=10.5,b=20.00002;
	cout<<"自动类型推导"<<endl;
	printf("%lf\n",sum(a,b));
	cout<<"显示指定类型"<<endl;
	printf("%lf",sum<double>(a,b));
	return 0;
} 
```

注意
* 自动推导类型需要推导出一致的类型
* 函数模板使用时必须确定`T`的类型
* 普通函数和函数模板都可调用时，先调用普通函数
* 如果类型和函数模板更匹配，则优先调用函数模板

**类模板**

示例：
```
#include<bits/stdc++.h>
using namespace std;
template<class T,class M>
class person
{
public:
	T name;
	M age;
	person(T a,M b):name(a),age(b){}
};
int main()
{
	person<string,int> p("cndh",18);
	cout<<p.name<<endl;
	cout<<p.age<<endl;
	return 0;
} 
```
注意：
* 类模板不能自动推导类型
* 类模板可以在模板参数列表中指定默认类型
* 类模板中定义的函数在调用时才创建

---

## c++深拷贝和浅拷贝的区别

>**浅拷贝** （默认方式）：将原对象的引用直接赋给新对象，只是原对象的一个引用。

>**深拷贝**： 创建一个新的对象，将原对象的各项属性拷贝过来，深拷贝会在堆中额外申请内存来储存数据，当数据成员中有指针时，必须要用深拷贝。

* 因为申请了新的内存，所以深拷贝改变新对象的属性对原对象没有影响，但是浅拷贝会影响
* 当成员中有指针时，必须用深拷贝。因为浅拷贝的新指针和旧指针都指向同一块内存，在新对象和旧对象析构时，已经释放的内存会被再次释放，这时会出现错误。

***

## c++多态

编译时多态：

* 编译器多态是通过函数重载和模板实现的。在编译时，根据函数的参数类型或模板参数类型，编译器会选择合适的函数或模板实例化。
* 编译器多态是在编译时确定函数调用，因此它的性能较高。
* 编译器多态不需要使用虚函数和基类指针或引用，可以直接根据函数的参数类型或模板参数类型来确定函数调用。

运行时多态：
* 运行时多态是通过继承和虚函数实现的。当基类的指针或引用指向派生类对象时，通过虚函数的动态绑定，可以在运行时确定要调用的函数实现。
* 运行时多态需要使用虚函数和基类指针或引用来实现，这样可以在运行时根据实际对象的类型来确定调用哪个函数。
* 运行时多态在运行时才能确定具体的函数调用，因此它的性能相对较低。

***override的作用***

保证在派生类中声明的重载函数，与基类的虚函数有相同的签名，核心作用就是用于编译期代码检查。

***final***

阻止类的进一步派生和虚函数的进一步重写，同时也是一种名为去虚拟化的优化技巧，相当于把运行期多态转换为了编译期多态，提高了执行效率。

***多继承存在的问题***

命名冲突

***向上转型***

向上转型是子类指针转换成父类指针

`Parent* p =new son();`

***向下转型***

因为父类指针不能操作子类独有的函数，即使父类指针指向子类的对象也不行，所以需要向下转型

向下转型有两种方式`dynamic_cast`和`static_cast`,前者更加安全一些

例如：
```
Parent* pSon=new Son();
Son* s=dynamic_cast<Son*>(pSon);
```

***
## 虚函数与纯虚函数

**虚函数**
在类中声明时前面带有virtual关键字的函数，如：
```
class A {
	virtual void example();
}
```
**纯虚函数**
```
在虚函数后面加`=0`
class A {
	virtual void example() = 0;
}
```
* 虚函数可以在父类中实现，也可以被子类重写实现，是实现运行时多态的方式之一
* 纯虚函数不可以在父类实现，必须由子类重写
* 含有纯虚函数的类被称为抽象类，抽象类不能实例化
* 抽象类的子类如果要实例化，则必须重写纯虚函数

**虚函数怎么实现的？真的更慢吗？**
* 虚函数是通过虚函数表实现的，每个类都有自己的虚表，对象的首地址处存放有指向虚表的指针。
* 当具体调用哪个虚函数可以在编译期间确定的时候，虚函数不一定更慢。

## c++智能指针

**内存泄漏**：
* 指因某些原因造成程序未能释放已不再使用的内存。内存泄漏并不是内存消失了，而是由于程序设计的问题，失去对某块内存的控制，导致无法利用该块内存。

* 内存泄漏会导致程序响应越来越慢，甚至崩溃

* 一般有2种内存泄漏，一种是堆区分配的内存没有及时释放，一种是套接字、文件描述符等没有释放，2种情形都会导致资源的浪费

**RALL**

* RAII（Resource Acquisition Is Initialization）是一种将对象生命周期和资源绑定的技术
* 对象创建时获取资源，析构时释放资源

智能指针就具有RALL的特性

**auto_ptr**

c++98中就已经提供了智能指针auto_ptr

例如：`auto_ptr<int> p(new int)`就相当于 `int * p=new int`

auto_ptr的局限性：
* 拷贝或者赋值会导致原指针变为`NULL`，如`p1=p2`后，`p2变成了NULL`
* 不支持对象数组的内存管理

**unique_ptr**



不能直接进行赋值或者拷贝构造，如：`p1 = p2`和`unique_ptr<int> p1(p2)`

如果要强行执行的话要加上`move`，如：`p1 = std::move(p2)`和`unique_ptr<int> p1(std::move(p2))`

**shared_ptr**

通过**引用计数**(`use_count()`)的方式来实现多个`shared_ptr`对象之间共享资源

* shared_ptr在其内部，给每个资源都有一份计数表，用来记录该份资源被几个指针共享
* 在对象被销毁时(也就是析构函数调用)，就说明自己不使用该资源了，对象的引用计数减一
* 如果引用计数是0，就说明自己是最后一个使用该资源的对象，必须释放该资源
* 如果不是0，就说明除了自己还有其他对象在使用该份资源，不能释放该资源，否则其他对象就成野指针了

注意：两个对象交叉使用**shared_ptr**(互相获得对方的share指针),会导致内存泄漏

**weak_ptr**

专门为了解决上面的**shared_ptr**的问题，不支持RALL，不释放资源，不增加或减少引用计数

具体参考[相关链接](https://blog.csdn.net/cpp_learner/article/details/118912592?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166191088916782414982504%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166191088916782414982504&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-118912592-null-null.142^v42^pc_rank_34,185^v2^control&utm_term=c%2B%2B%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88&spm=1018.2226.3001.4187)

***

## const 和 volatile辨析

**const**
* 被const修饰的变量被视为一个常量，使得变量具有只读属性
* const修饰的变量不是一个真正的只读变量，它只是告诉编译器该变量**不能出现在赋值符号的左边**

***const修饰指针变量有以下3种情况***
1. const 修饰指针指向的内容，则内容为不可变量。
```
const int *p = 8; //指向的内容8不可变
*p=6; //错误
```
2. const 修饰指针，则指针不可变
```
int a=8;
int* const p = &a;
*p = 9; // 正确
int  b = 7;
p = &b; // 错误
```
3. const 修饰指针和指针指向的内容，则指针和指针指向的内容都为不可变量。
```
int a = 8, b = 2;
const int * const  p = &a;
*p=1; //错误
p=&b; //错误
```

***const 修饰对象和成员函数***
* 被const修饰的对象(常对象)或者成员函数(常函数)内不能修改类的成员变量，如果要修改需要给对应的成员变量加mutable关键字
* 常对象只能修改常函数

**volatile**

本意为易变的，有以下特点

* volatile指出变量是随时可能变化的，每次使用需要重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。
* 被volatile修饰的变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。

>***一个变量可以同时被const和volatile修饰吗？***

可以。const volatile表示一个变量在程序编译期不能被修改且不能被优化；在程序运行期，每次必须从内存中加载变量的值。

## NULL 和 nullptr的区别是什么，为什么引入nulllptr？
* 主流编译器中，`NULL`实际上是一个整数常量，被定义为 0，在 C++11 之前，当我们想要将一个指针初始化为空时，我们通常使用 NULL；
* `nullptr` 是 C++11 中引入的新的关键字，专门用于表示空指针，它不是整数类型，而是特殊的指针类型`nullptr_t`。

***引入nullptr的原因***
1. NULL是整数类型，用户调用foo(NULL)的时候，不能区分调用的是foo(int)还是foo(int*)函数；
2. 主流编译器中NULL值为0，通过0表示一个无效地址，但是有的架构下，0地址有特定用途，而`nullptr`指向的永远是一个无效地址。

## git fetch和git pull的区别
* git fetch是将远程主机的最新内容拉到本地，用户在检查了以后决定是否合并到工作本机分支中。
* 而git pull 则是将远程主机的最新内容拉下来后直接合并，即：git pull = git fetch + git merge，这样可能会产生冲突，需要手动解决。

>git 连接/添加远程仓库
git remote add 仓库名 地址

## delete[]是怎样知道数组长度的？
没有标准实现，一种常见的实现方法是，申请内存时，会在返回的指针前面存放这段内存的大小，调用delete[]的时候，就可以知道数组长度了。

## 程序是从main 函数开始执行的吗？
不是，程序在执行前，会经历一个从磁盘加载程序到内存的过程，这个过程会执行非静态全局变量的初始化。

# python
## python的垃圾回收机制
>python采用的是**引用计数**为主，**标记—清除**和**分代收集**为辅的策略。

**引用计数**
每个对象维护一个字段来记录对象被引用的次数，当新的引用指向该对象的时候，引用计数的值加1,当某个引用失效时，引用计数值减一。当引用计数的值为0时，会释放占用的内存空间。

缺点：
* 需要额外的空间维护引用次数
* 对象的循环引用会导致内存泄漏

引用计数增加的情况：

* 对象被创建，例如 a = 23
* 对象被引用，例如 b = a
* 对象被作为参数，传入到一个函数中，例如 fun(a)
* 对象被作为一个元素，存储在容器中

引用计数减少的情况：

* 对象的别名被显式销毁，例如 del a
* 对象的别名被赋予新的对象，例如 a = 24
* 一个对象离开它的作用域，例如 f 的函数执行完毕时，func函数中的局部变量
* 对象所在的容器被销毁，或从容器中删除对象

**分代回收**

* 分代回收是一种以空间换时间的方式，Python将内存根据对象的存活时间划分为不同的集合，每一个集合称为一个代，Python将内存分为了3“代”，分别代表**年轻代**（第0代）、**中年代**（第1代）、**老年代**（第2代），它们对应的是3个链表，它们的垃圾收集频率随着对象的存活时间的增大而减小

* 新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾回收机制就会被触发，把那些可以被回收的对象被回收掉，而那些不会被回收的对象就会被移动到中年代，依次类推， 老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期中。

**标记--清除**

是一种基于追踪回收（tracking GC）技术实现的垃圾回收算法。它分为两个阶段：
 1. 标记阶段，GC会把所有的活动对象打上标记
 2. 把那些没有标记的对象（非活动对象）进行回收

**如何判断哪些是活动对象，哪些是非活动对象？**

对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从跟对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。
# deep learning
## 判别模型和生成模型

判别模型：直接学习条件概率$P(y|x)$
生成模型：学习联合概率$P(x,y)$，然后可以计算条件概率$P(y|x)$以及其他信息，需要的数据量较大


简单说，要判断一个苹果是好是坏，判别模型会直接给出是好的概率和是坏的概率，而生成模型分别学习出两种苹果各自对应的模型，然后将要预测的苹果的特征分别输入不同模型，然后比较两个模型输出概率的大小，选出合适的类别

判别模型：
* 感知机
* k近邻
* 决策树
* 逻辑思蒂回归
* svm
* boosting
* 最大熵模型

生成模型：
* 朴素贝叶斯
* 混合高斯模型
* 隐马尔可夫模型

## 转置卷积和空洞卷积

***转置卷积***
>在语义分割中，会使用卷积层进行特征提取，然后通过转置卷积做上采样，恢复为原先的尺寸，这样才可以对原来的图像中每个像素都进行分类。**转置卷积不是卷积的逆运算**

基本步骤：

* 在特征图**中间**(元素和元素之间)填充s-1行，s为步长
* 在特征图**四周**填充k-p-1行，k为卷积核大小，p为padding
* 将kernel上下、左右翻转（中心对称，顺时针旋转180度）
* 做kernel_size不变，s和p均为1的卷积即可

***空洞卷积***
* 在卷积核相邻元素之间插入0,具体插入膨胀率(dilation rate)-1个0，然后再做卷积
* 主要目的是扩大感受野

## 数据集不平衡的处理方式

1. 数据增广
	* 进行一定的旋转缩放
	* RGB三通道提取三张图片
	* 高斯模糊
2. 人工合成数据
3. 给每种类别赋予权值，样本少的类别权值可以大一些，样本多的类别权值小一些

## tensorflow和pytorch的区别

1. tf是谷歌开源的深度学习框架，pytorch是facebook开源的深度学习框架
2. 在tf1.0时，tf只支持静态的计算图，而pytorch支持动态的计算图，但是tf2.0也支持动态计算图了
3. tf的api更详细更丰富，pytorch的代码更简洁
4. tf有tensorboard这样的可视化工具，但实际上现在pytorch也能使用tensorboard

## transformer中的位置编码

>为什么需要位置编码？
* 位置和词语的顺序是任何语言的重要组成部分。它们定义了语法，从而决定了句子的实际语义。循环神经网络（RNN）本质上考虑了词语的顺序；它们按照顺序逐个解析句子中的词语。这样可以将词语的顺序整合到RNN的主干中。
* Transformer架构放弃了循环机制，转而采用**多头自注意机制**，大大加快训练时间。从理论上讲，它可以捕捉到句子中更长的依赖关系。由于句子中的**每个词语同时通过Transformer的编码器/解码器，模型本身对于每个词语的位置/顺序没有任何概念。**

>位置编码的计算？

$$
\left.\overrightarrow{p_t}^{(i)}=f(t)^{(i)}:=\left\{\begin{array}{ll}\sin(\omega_k.t),&\mathrm{if~}i=2k\\\cos(\omega_k.t),&\mathrm{if~}i=2k+1\end{array}\right.\right.
$$
其中，t代表位置，i代表维度。p代表第t个位置，第i个维度的值。$\omega_k$的计算如下：
$$
\omega_k=\frac1{10000^{2k/d}}
$$

有以下特点：
* 奇数维度之间或者偶数维度之间周期不同。
* 除了表示绝对位置信息外，还可以很好的表示相对位置信息。给定k,存在一个固定的与k相关的线性变换矩阵，从而由pos的位置编码线性变换而得到pos+k的位置编码。这个相对位置信息可能可以被模型发现而利用。因为绝对位置信息只保证了各个位置不一样，但是并不是像0,1,2这样的有明确前后关系的编码。

>CV中使用位置编码

与nlp中类似，cv中的每个像素和patch也有自己的位置信息，通常cv中位置编码有以下两种：

* 绝对位置编码：一般是可学习的，实现非常简洁，初始化一个形状和经过patch_embedding后的输出x相同的参数，然后直接加到x上，在训练阶段一起训练，有点像加了一个可学习的bias，VIT中使用的就是这种方式。
* 相对位置编码：绝对位置编码是在patch_embedding之后，计算自注意力(Q,K,V)之前，而相对位置编码是在计算自注意力的时候加入的，如下式
$$
\text{Attention}(Q,K,V)=\text{SoftMax}(\frac{QK^T}{\sqrt{d}}+B)V
$$
在swin transformer中，将二维位置信息转换为一维位置信息，然后去根据相对位置偏移表查询具体的值，位置偏移表的值是训练出来的，在文章中，相对位置编码效果好于绝对位置编码。具体参考[这里](https://blog.csdn.net/qq_43733107/article/details/127077056)

>为什么往往小数据集上卷积效果好于tranformer?
* 在小数据集上，相比卷积transformer缺少内在偏置，因此需要加入相对位置编码来解决这个问题，而对于特大数据集，transformer就可以学习到卷积的内在偏置，即这也是为什么在小数据集上transformer的效果不如卷积，而在大数据集上，transformer效果优于卷积。

## 自注意力和注意力的区别

注意力机制的查询和键是不同来源的，而自注意力机制的查询和键则都是来自于同一组的元素，如对于一张图片，q和k都来自于这张图片的patch或者特征。

>个人对于DETR的decoder中的q，k,v的理解

query是每张图设置的预测的proposals的数量，例如一张图的gt有20个bbox，然后query为100，那么网络会产生100个proposals，然后用匈牙利算法求得100个query和20个bbox的最优匹配

对于decoder的多头注意力，我理解的是kv来自encoder是因为encoder中将图像的特征进行了编码，然后由于需要产生100个proposals，所以就用外部的q来计算encoder产生的k的权重信息，比如qk^T->[16,100,32]*[16,32,576]=[16,100,576]，这里[100,576]代表了100个query在576个特征上的权重或者相似度信息，然后乘v[16,576,32]，输出是[16,100,32]，reshape为[100,2,256]，encoder的输出[576,2,256]经过decoder后映射为[100,2,256]，因此加入的query可能是为了学习encoder的输出中的特征信息，然后将特征的维度降到100，然后从这100个proposals中取匹配最佳的gt。


