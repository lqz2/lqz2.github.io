---
title: 参考资料合集
date: 2023-08-11 17:28:17
categories: 资料
math:
tags:
---
<!-- TOC -->

- [这里记录了一些有价值的参考资料:rainbow::rainbow::rainbow:](#这里记录了一些有价值的参考资料rainbowrainbowrainbow)
    - [第一周:rainbow:](#第一周rainbow)
    - [第二周:rainbow:](#第二周rainbow)

<!-- /TOC -->
## 这里记录了一些有价值的参考资料:rainbow::rainbow::rainbow:

### 第一周:rainbow:

1.  了解了在线深度学习可视化辅助工具wandb
2.  关于结构性相似度（SSIM）的论文，《Image quality assessment: from error visibility to structural similarity》
3.  在TarDAL中使用显著性检测从红外图像中生成mask的网络，《R3Net: Recurrent Residual Refinement Network for Saliency Detection》
4.  GAN网络中为什么判别器训练的越好，生成器梯度消失越严重，参考(http://t.csdn.cn/jVstu)
5.  在TarDAL论文中，判别器损失函数使用了WGAN-div损失函数，即引入了Wasserstein散度，具体参考(https://zhuanlan.zhihu.com/p/25071913)，(http://t.csdn.cn/tvs1K)，(http://t.csdn.cn/5Wf1s)，总的来说WGAN可以帮助GAN网络的训练变的更加稳定。
6.  关于图像融合评价指标的计算：(http://t.csdn.cn/OPA8W)
### 第二周:rainbow:
1. linux下通过软连接切换cuda版本，首先 ls /usr/local | grep cuda查看已安装的cuda版本，然后sudo ln -snf /usr/local/cuda-10.0 /usr/local/cuda建立软连接即可，-s表示创建软连接，-n表示软连接已存在则删除，-f表示强制覆盖，具体可参考http://t.csdn.cn/UTNii，如果没有root权限，可通过修改~/.bashrc文件的方法切换，具体参考(http://t.csdn.cn/3CPV8)
2. vscode远程调试中文件路径无法找到时，可以将launch.json中pargram设置为运行文件，cwd设置为运行目录，这样即可正常调试。
3. 调试过程查看梯度：在vscode调试时，尝试在调试控制台查看模型的梯度，但是只能在变量中看到nn.module.parameters()函数，要具体查看参数需要通过代码将梯度打印出来，如for name, param in self.detect.net.named_parameters(): print(name, param.grad)，经过调试得出，在优化器更新参数时，只有模型的loss经过backward()回传才会计算梯度，比如gloss=a*floss+b*dloss，如果a=0，那么gloss.backward()后，会计算模型d梯度而不会计算模型f的梯度。
4. pytorch中permute函数和view()/reshape()函数的区别，前者是在维度上互换或者重新排列，后者相当于将所有元素重新取出再排列。详细参考(http://t.csdn.cn/P5J05)，同时torch.nn.Flatten与torch.flatten也有一点小区别，即前者默认从维度1开始，后者默认从维度0开始。
5. einops库中的矩阵操作与einsum矩阵乘法，参考：(http://t.csdn.cn/Z7jsq)
6. 关于dataloader中的collate_fn函数，他的作用是手动调整一个batch中的数据的组织方式，其传入参数为batch(一个大小为batchsize的list)，具体参考(http://t.csdn.cn/L9O7A)，如果__getitem__函数中出现标签为空的情况，可以通过collate_fn进行改动，参考(http://t.csdn.cn/ukPp8)
7. pytorch中torchvision.transform.Resize()和torch.nn.functions.interpolate的区别：前者是基于插值实现的，用于调整图像的大小，后者常用于对特征图进行上采样等操作。更多关于图像预处理的方法，参考torchvision官方文档(https://pytorch.org/vision/0.15/transforms.html#transforms-scriptability)
8. 计算模型的参数量以及计算量的方法，参考(http://t.csdn.cn/n8Y1C)，(http://t.csdn.cn/V9qdL)
9. IEEE Conference latex模板使用注意事项，参考(http://t.csdn.cn/d7cdR)，latex列表的使用，参考(http://t.csdn.cn/UbEiH)
10. ppt绘图后使用vba宏一键导出为pdf并裁剪，参考(http://t.csdn.cn/ynrXM)，这里vba代码中使用pdfcrop在我的电脑中失效，可以shell代码改为Shell "pdfcrop " & strNotes & sExt & " " & strNotes & sExt，然后在前面加上ChDir sPath更改工作路径，或者手动使用pdfcrop进行pdf裁剪
11. 科研作图和表格参考：(https://zhuanlan.zhihu.com/p/603088040)
12. 统计模型参数量和计算量，参考(http://t.csdn.cn/DZ7SL)
13. etc.，et al.，i.e.，e.g.的区别，参考(https://zhuanlan.zhihu.com/p/85630819)
14. 图像的相关系数计算，参考(http://t.csdn.cn/g1l9V)
15. 关于范数，0范数表示非零元素个数，1范数表示所有元素绝对值之和，2范数表示所有元素间平方和，无穷范数表示所有元素最大值，对于两个向量，L1范数又叫曼哈顿距离，是元素间的绝对误差和(差的绝对值求和)，而L2范数是欧氏距离，是元素间的平方差和。
16. 梯度裁剪nn.utils.clip_grad_norm_的使用，参考(http://t.csdn.cn/32FG4)，(http://t.csdn.cn/jY2ae)
17. 本地文件传输到远程服务器，远程服务器文件互相传输，参考：(https://cloud.tencent.com/developer/article/2092491)
18. 服务器防火墙设置，参考(http://t.csdn.cn/LwKP5)，(http://t.csdn.cn/KhAqh)
19. 关于自注意力的意义的详细解析，参考(https://zhuanlan.zhihu.com/p/410776234)
20. BatchNorm，LayerNorm，GroupNorm的区别，参考：(http://t.csdn.cn/FFnCE)
21. python广播机制的用法，参考：(http://t.csdn.cn/ch2qw)