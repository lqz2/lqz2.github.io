---
title: ZooKeeper学习
date: 2025-06-03 10:49:27
categories: 学习
math:
tags:
---
<!-- TOC -->

- [ZooKeeper学习](#zookeeper学习)
    - [ZooKeeper简介](#zookeeper简介)
    - [分布式环境下的数据协调问题](#分布式环境下的数据协调问题)
    - [一致性协议](#一致性协议)
        - [二阶段提交协议（2PC）](#二阶段提交协议2pc)
        - [三阶段提交协议（3PC）](#三阶段提交协议3pc)
    - [ZK如何保证数据一致性？](#zk如何保证数据一致性)
        - [消息广播](#消息广播)
        - [崩溃恢复](#崩溃恢复)
        - [选举leader的过程](#选举leader的过程)
    - [ZK的数据结构](#zk的数据结构)
    - [应用场景](#应用场景)
        - [数据发布和订阅](#数据发布和订阅)
        - [负载均衡](#负载均衡)
        - [分布式锁](#分布式锁)
            - [排他锁](#排他锁)
            - [共享锁](#共享锁)

<!-- /TOC -->
# ZooKeeper学习
## ZooKeeper简介
ZooKeeper是一个开源的分布式协调服务框架，其一致性是通过基于 Paxos 算法的 ZAB 协议完成的。其主要功能包括：配置维护、分布式同步、集群管理等。
## 分布式环境下的数据协调问题
- 分布式环境下，无法保证顺序：单机环境下A和B的顺序是由调用顺序决定的，而在分布式环境下，A和B的顺序可能会因为网络延迟等因素而改变。
- 分布式环境下，无法明确执行结果：分布式环境下，A即使执行成功了，如果网络传输超时了，也无法判断A是否执行成功。
- 分布式环境下，无法保证数据一致性：分布式环境下，多个节点可能会同时修改同一份数据，导致数据不一致。

## 一致性协议
### 二阶段提交协议（2PC）
一种分布式事务协议，分为准备（投票）阶段和提交阶段。
投票阶段：
1. 协调者向所有参与者发送prepare请求，通知参与者执行事务
2. 参与者收到请求后，执行事务并记录undo日志和redo日志，但不提交事务
3. 参与者向协调者发送事务执行结果（Yes或者No）

提交阶段：
1. 如果所有参与者都返回yes，协调者向所有参与者发送commit请求，通知参与者提交事务，参与者提交事务并返回ack给协调者
2. 如果有参与者返回no，协调者向所有参与者发送rollback请求，通知参与者回滚事务，参与者根据undo日志回滚事务并返回ack给协调者

存在的问题：
1. 容错低，有一个参与者挂了，整个事务就无法完成
2. 性能低，同步期间所有资源被锁定，资源利用率低
3. 数据不一致，协调者发送commit命令期间挂了，有的参与者提交了事务，有的没有提交。

### 三阶段提交协议（3PC）
在2PC的基础上增加了一个选票预收集阶段，分为预投票、投票和提交三个阶段。
- 预投票阶段：协调者向所有参与者发送请求，询问是否可以执行事务，参与者根据自身状态返回Yes或No。
- 投票阶段：如果所有参与者都返回Yes，协调者向所有参与者发送prepare请求，参与者执行事务并记录undo日志和redo日志；如果有参与者返回No，协调者向所有参与者发送中断请求，中断事务。
- 提交阶段：流程和2PC类似

3PC仍然没有解决一致性问题

## ZK如何保证数据一致性？
ZK主要通过ZAB协议来保证数据的一致性，ZAB协议包括两种工作模式崩溃恢复和消息广播。
### 消息广播
和二阶段提交的思想类似。当客户端写请求到来时，leader会生成一个事务请求，发送给集群的follower，follower收到请求后，执行事务并写入日志，返回结果（yes 或者 no）给leader。如果半数以上的follower返回yes，leader就会向所有follower发送commit请求，follower接受到请求后提交事务。

要注意的是：
- 投票阶段不需要所有follower都返回yes，只需要半数以上的follower返回yes即可。
- leader会维护一个队列保证请求顺序性
- ZAB 中还定义了一个 全局单调递增的事务 ZXID ，它是一个 64 位 long 型，其中高 32 位表示 epoch 年代，低 32 位表示递增的事务 id。epoch 是会根据 Leader 的变化而变化的，当一个 Leader 挂了，新的 Leader 上位的时候，年代（epoch）就 +1，而低 32 位则从0开始重新计数。这个设计也保证了顺序性。

### 崩溃恢复
当leader出现故障或者集群中没有过半服务器与leader通信时，ZK会进行崩溃恢复。主要分三步：
1. 选举新的leader：ZK会通过投票的方式选举出一个新的leader
2. leader获取所有follower提交的最大事务集合
3. follower从leader那里同步最新的事务集合，未同步的follower不会被加入到可用列表

过程中需要保证：
- leader上提交过的事务，最终被所有服务器都提交
- leader上未提交的事务被丢弃

### 选举leader的过程
选举leader的过程简单来说就是发起投票，接受投票，根据收到的投票改变自己的投票，直到某个节点获得过半数的投票为止。
- 开始时，每个节点给自己投票，投票内容为`自己机器ID+自己提交的最大事务ZXID`，然后把投票内容发送给其他节点。
- 收到投票后先比较ZXID，如果ZXID相同，则比较机器ID。如果收到的投票比自己的投票大，则更新自己的投票内容为收到的投票内容，并将自己的投票发送给其他节点。

## ZK的数据结构
ZK使用树来维护数据，每个节点都是一个ZNode，ZNode又分为三大类
- 持久性节点：创建后一直存在于服务器，直到主动删除
- 临时性节点：创建后只在客户端会话存活期间存在，客户端断开连接后自动删除
- 顺序节点：创建后会在节点名称后加上一个自增的数字，表示顺序

## 应用场景
### 数据发布和订阅
Zookeeper 通过推拉相结合的方式实现客户端与服务端的交互：
客户端向服务端注册节点，一旦相应节点的数据变更，服务端就会向“监听”该节点的客户端发送 Watcher 事件通知，客户端接收到通知后需要 **主动** 到服务端获取最新的数据。比如全局配置信息管理

### 负载均衡
可以通过临时节点实现负载均衡
具体地，我们需要在集群的每一个 Server 中都使用 Zookeeper 客户端连接 Zookeeper 服务端，同时用 Server 自身的地址信息在服务端**指定目录下创建临时节点**。当客户端请求调用集群服务时，首先通过 Zookeeper 获取该目录下的节点列表 （即所有可用的 Server），随后根据不同的负载均衡策略将请求转发到某一具体的 Server。

### 分布式锁
ZK的分布式锁也是通过临时节点实现的。

#### 排他锁
因为创建节点的唯一性（ZXID），我们可以让多个客户端同时创建一个临时节点，创建成功的就说明获取到了锁 。然后没有获取到锁的客户端也像上面选主的非主节点创建一个 监听器 进行节点状态的监听，如果这个互斥锁被释放了可以调用回调函数重新获得锁。如果客户端挂了，那么临时节点也就会被删除，其他客户端就可以重新获取锁，无需担心锁的释放问题

#### 共享锁
因为ZXID的有序性，所以创建的节点也是有序的。当创建节点时，如果比自己小的节点都是读请求，则可以获取到锁，如果比自己小的节点有写请求，则需要等待写请求完成后才能获取锁。

羊群效应：
集群很大时，子节点列表会很大，会创建大量的监听器，但是只有最近的节点接到事件后可以执行，所以造成了资源浪费。
改进：
读请求只监听比自己小的最近的写请求的节点的状态，写请求只监听比自己小一号的节点的状态。这样就可以减少监听器的数量，避免羊群效应。








